% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/redshift.R
\name{redshift_insert_via_copy_from_s3}
\alias{redshift_insert_via_copy_from_s3}
\title{Dumps a data frame to disk, copies to S3 and runs COPY FROM on Redshift}
\usage{
redshift_insert_via_copy_from_s3(df, table, db)
}
\arguments{
\item{df}{\code{data.frame}}

\item{table}{Redshift schema and table name (separated by a dot)}

\item{db}{database reference by name or object}
}
\description{
Note that the related database's YAML config should include \code{s3_copy_bucket} and \code{s3_copy_iam_role} fields with \code{attr} type pointing to a staging S3 bucket (to which the current node has write access, and the Redshift IAM Role has read access) and the full ARN of the Redshift IAM Role.
}
